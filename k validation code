import pandas as pd
from sklearn.model_selection import KFold, cross_val_score
from sklearn.linear_model import LinearRegression
import numpy as np

# 1. Create a sample dataset (replace with your actual data)
data = {
    'age': [25, 30, 35, 40, 45, 50, 28, 33, 38, 43, 48, 53, 27, 32, 37],
    'height': [170, 175, 180, 165, 172, 178, 168, 173, 179, 167, 171, 176, 169, 174, 181],
    'weight': [70, 75, 80, 68, 72, 78, 69, 74, 79, 67, 71, 77, 70, 76, 82]
}
df = pd.DataFrame(data)

# Define features (X) and target (y)
X = df[['age', 'height']]
y = df['weight']

# 2. Initialize the KFold object
n_splits = 5  # Number of folds
kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

# 3. Initialize the model (e.g., Linear Regression)
model = LinearRegression()

# 4. Perform K-fold cross-validation
# The 'cross_val_score' function handles the splitting and evaluation automatically
scores = cross_val_score(model, X, y, cv=kf, scoring='neg_mean_squared_error')

# Convert negative mean squared error to positive RMSE for better interpretation
rmse_scores = np.sqrt(-scores)

# 5. Print the results
print(f"Individual RMSE scores for each fold: {rmse_scores}")
print(f"Mean RMSE across all folds: {rmse_scores.mean():.2f}")
print(f"Standard deviation of RMSE scores: {rmse_scores.std():.2f}")
